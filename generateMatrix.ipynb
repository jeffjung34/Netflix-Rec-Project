{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.sparse.linalg import norm\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shows movie dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie_ID</th>\n",
       "      <th>Year</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2003</td>\n",
       "      <td>Dinosaur Planet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2004</td>\n",
       "      <td>Isle of Man TT 2004 Review</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1997</td>\n",
       "      <td>Character</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1994</td>\n",
       "      <td>Paula Abdul's Get Up &amp; Dance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2004</td>\n",
       "      <td>The Rise and Fall of ECW</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Movie_ID  Year                          Name\n",
       "0         1  2003               Dinosaur Planet\n",
       "1         2  2004    Isle of Man TT 2004 Review\n",
       "2         3  1997                     Character\n",
       "3         4  1994  Paula Abdul's Get Up & Dance\n",
       "4         5  2004      The Rise and Fall of ECW"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_dataset = \"Dataset/Netflix_Dataset_Movie.csv\"\n",
    "movie_df = pd.read_csv(movie_dataset)\n",
    "movie_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shows user dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_ID</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Movie_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>712664</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1331154</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2632461</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44937</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>656399</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   User_ID  Rating  Movie_ID\n",
       "0   712664       5         3\n",
       "1  1331154       4         3\n",
       "2  2632461       3         3\n",
       "3    44937       5         3\n",
       "4   656399       4         3"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_dataset = \"Dataset/Netflix_Dataset_Rating.csv\"\n",
    "user_df = pd.read_csv(user_dataset)\n",
    "user_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below calculation shows how many movies are rated by no users in our dataset. Because these movies have 0 ratings for all users, we will exclude them from our data. Since there are 16,420 movies that are unrated, our user-movie matrix will have signicantly fewer columns than the total number of movies in the dataset.\n",
    "\n",
    "Sparsity Reduction: Movie recommendation datasets are typically sparse, meaning most movies are not rated by most users. Removing movies that have zero ratings can significantly reduce the sparsity of our matrix, making matrix factorization techniques more effective and computationally feasible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of movies not rated by users: 16420\n"
     ]
    }
   ],
   "source": [
    "movies_in_movie_df = set(movie_df['Movie_ID'])\n",
    "movies_in_user_df = set(user_df['Movie_ID'])\n",
    "unrated_movies = movies_in_movie_df - movies_in_user_df\n",
    "\n",
    "print(f\"Number of movies not rated by users: {len(unrated_movies)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine these two dataframe objects in order to initalize our matrix. We assume that an \"unrated\" movie has a rating 0 for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(user_df, movie_df, on='Movie_ID')\n",
    "rating_matrix = merged_df.pivot_table(index='User_ID', columns='Name', values='Rating')\n",
    "rating_matrix = rating_matrix.fillna(0)\n",
    "rating_matrix = rating_matrix.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pivot Table Size: 143458 rows, 1342 columns\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Name</th>\n",
       "      <th>10</th>\n",
       "      <th>10 Things I Hate About You</th>\n",
       "      <th>101 Dalmatians II: Patch's London Adventure</th>\n",
       "      <th>11:14</th>\n",
       "      <th>13 Ghosts</th>\n",
       "      <th>18 Again</th>\n",
       "      <th>1984</th>\n",
       "      <th>2 Fast 2 Furious</th>\n",
       "      <th>200 Cigarettes</th>\n",
       "      <th>2010: The Year We Make Contact</th>\n",
       "      <th>...</th>\n",
       "      <th>Xena: Warrior Princess: Season 3</th>\n",
       "      <th>Xena: Warrior Princess: Series Finale</th>\n",
       "      <th>Y Tu Mama Tambien</th>\n",
       "      <th>Yellow Submarine</th>\n",
       "      <th>Yi Yi</th>\n",
       "      <th>Yojimbo</th>\n",
       "      <th>Young Black Stallion</th>\n",
       "      <th>Youngblood</th>\n",
       "      <th>Yu-Gi-Oh!: The Movie</th>\n",
       "      <th>Zorro</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 1342 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Name      10  10 Things I Hate About You  \\\n",
       "User_ID                                    \n",
       "6        0.0                         0.0   \n",
       "7        0.0                         0.0   \n",
       "79       0.0                         0.0   \n",
       "97       0.0                         0.0   \n",
       "134      0.0                         5.0   \n",
       "169      0.0                         0.0   \n",
       "183      0.0                         0.0   \n",
       "188      0.0                         0.0   \n",
       "195      0.0                         0.0   \n",
       "199      0.0                         0.0   \n",
       "\n",
       "Name     101 Dalmatians II: Patch's London Adventure  11:14  13 Ghosts  \\\n",
       "User_ID                                                                  \n",
       "6                                                0.0    0.0        0.0   \n",
       "7                                                0.0    0.0        0.0   \n",
       "79                                               3.0    0.0        0.0   \n",
       "97                                               0.0    0.0        0.0   \n",
       "134                                              0.0    0.0        0.0   \n",
       "169                                              0.0    0.0        0.0   \n",
       "183                                              0.0    0.0        0.0   \n",
       "188                                              0.0    0.0        0.0   \n",
       "195                                              0.0    0.0        0.0   \n",
       "199                                              0.0    0.0        0.0   \n",
       "\n",
       "Name     18 Again  1984  2 Fast 2 Furious  200 Cigarettes  \\\n",
       "User_ID                                                     \n",
       "6             0.0   4.0               0.0             0.0   \n",
       "7             0.0   0.0               3.0             0.0   \n",
       "79            0.0   0.0               2.0             0.0   \n",
       "97            0.0   0.0               0.0             0.0   \n",
       "134           0.0   0.0               5.0             0.0   \n",
       "169           0.0   0.0               0.0             0.0   \n",
       "183           0.0   0.0               0.0             0.0   \n",
       "188           0.0   0.0               0.0             0.0   \n",
       "195           0.0   0.0               0.0             0.0   \n",
       "199           0.0   0.0               3.0             0.0   \n",
       "\n",
       "Name     2010: The Year We Make Contact  ...  \\\n",
       "User_ID                                  ...   \n",
       "6                                   0.0  ...   \n",
       "7                                   0.0  ...   \n",
       "79                                  0.0  ...   \n",
       "97                                  0.0  ...   \n",
       "134                                 0.0  ...   \n",
       "169                                 0.0  ...   \n",
       "183                                 0.0  ...   \n",
       "188                                 0.0  ...   \n",
       "195                                 0.0  ...   \n",
       "199                                 0.0  ...   \n",
       "\n",
       "Name     Xena: Warrior Princess: Season 3  \\\n",
       "User_ID                                     \n",
       "6                                     0.0   \n",
       "7                                     0.0   \n",
       "79                                    0.0   \n",
       "97                                    0.0   \n",
       "134                                   0.0   \n",
       "169                                   0.0   \n",
       "183                                   0.0   \n",
       "188                                   0.0   \n",
       "195                                   0.0   \n",
       "199                                   0.0   \n",
       "\n",
       "Name     Xena: Warrior Princess: Series Finale  Y Tu Mama Tambien  \\\n",
       "User_ID                                                             \n",
       "6                                          0.0                0.0   \n",
       "7                                          0.0                0.0   \n",
       "79                                         0.0                0.0   \n",
       "97                                         3.0                0.0   \n",
       "134                                        0.0                0.0   \n",
       "169                                        0.0                0.0   \n",
       "183                                        0.0                0.0   \n",
       "188                                        0.0                0.0   \n",
       "195                                        0.0                4.0   \n",
       "199                                        0.0                0.0   \n",
       "\n",
       "Name     Yellow Submarine  Yi Yi  Yojimbo  Young Black Stallion  Youngblood  \\\n",
       "User_ID                                                                       \n",
       "6                     0.0    0.0      0.0                   0.0         0.0   \n",
       "7                     0.0    0.0      0.0                   0.0         0.0   \n",
       "79                    0.0    0.0      0.0                   0.0         0.0   \n",
       "97                    0.0    0.0      0.0                   0.0         0.0   \n",
       "134                   0.0    0.0      0.0                   0.0         0.0   \n",
       "169                   0.0    0.0      0.0                   0.0         0.0   \n",
       "183                   0.0    0.0      0.0                   0.0         0.0   \n",
       "188                   0.0    0.0      0.0                   0.0         0.0   \n",
       "195                   0.0    0.0      0.0                   0.0         0.0   \n",
       "199                   0.0    0.0      0.0                   0.0         0.0   \n",
       "\n",
       "Name     Yu-Gi-Oh!: The Movie  Zorro  \n",
       "User_ID                               \n",
       "6                         0.0    0.0  \n",
       "7                         0.0    0.0  \n",
       "79                        3.0    0.0  \n",
       "97                        0.0    0.0  \n",
       "134                       0.0    0.0  \n",
       "169                       0.0    0.0  \n",
       "183                       0.0    0.0  \n",
       "188                       0.0    0.0  \n",
       "195                       0.0    0.0  \n",
       "199                       0.0    0.0  \n",
       "\n",
       "[10 rows x 1342 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Pivot Table Size: {rating_matrix.shape[0]} rows, {rating_matrix.shape[1]} columns\")\n",
    "rating_matrix.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running similiarity metrics on our rating matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cosine similiarity: \n",
    "The cosine similarity between two vectors A and B is given by the formula: cos_similarity(A, B) = $\\frac{A \\cdot B}{\\lVert \\boldsymbol{A} \\rVert \\lVert \\boldsymbol{B} \\rVert}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since our dataset is large, for this technical demo, we will use the first 1,000 users to demonstrate the following similarity metrics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_rating_matrix = rating_matrix.head(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(matrix):\n",
    "    matrix_np = matrix.to_numpy()\n",
    "\n",
    "    # Initialize an empty similarity matrix\n",
    "    similarity_matrix = np.zeros((len(matrix), len(matrix)))\n",
    "\n",
    "    for i in range(len(matrix)):\n",
    "        for j in range(i, len(matrix)):  # Since matrix is symmetric, we only need to compute the upper half\n",
    "            # Indices of non-zero elements for both users\n",
    "            nz_indices_i = matrix_np[i, :] != 0\n",
    "            nz_indices_j = matrix_np[j, :] != 0\n",
    "            nz_indices_both = nz_indices_i & nz_indices_j\n",
    "\n",
    "            # Vectors for computation\n",
    "            vector_i = matrix_np[i, nz_indices_both]\n",
    "            vector_j = matrix_np[j, nz_indices_both]\n",
    "\n",
    "            # Skip if either vector is empty\n",
    "            if len(vector_i) == 0 or len(vector_j) == 0:\n",
    "                continue\n",
    "\n",
    "            # Compute cosine similarity\n",
    "            dot_product = np.dot(vector_i, vector_j)\n",
    "            norm_i = np.linalg.norm(vector_i)\n",
    "            norm_j = np.linalg.norm(vector_j)\n",
    "            similarity = dot_product / (norm_i * norm_j)\n",
    "\n",
    "            # Fill the similarity matrix\n",
    "            similarity_matrix[i, j] = similarity\n",
    "            similarity_matrix[j, i] = similarity\n",
    "\n",
    "    return similarity_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 movies recommended for User 6:\n",
      "Name\n",
      "American Beauty                          2.778856\n",
      "Ghost                                    2.221978\n",
      "Speed                                    1.930027\n",
      "The Wizard of Oz: Collector's Edition    1.882315\n",
      "Jaws                                     1.869414\n",
      "Being John Malkovich                     1.860085\n",
      "Patch Adams                              1.825309\n",
      "Bend It Like Beckham                     1.821213\n",
      "Sideways                                 1.786273\n",
      "National Lampoon's Vacation              1.747065\n",
      "dtype: float64\n",
      "Execution time of the program is:  24.084681034088135\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "def compute_for_user(user, matrix):\n",
    "    cosine_sim_matrix = cosine_similarity(matrix)\n",
    "\n",
    "    cosine_sim_df = pd.DataFrame(cosine_sim_matrix, index=matrix.index, columns=matrix.index)\n",
    "\n",
    "    # Find the similarity values for User 6 and exclude user \n",
    "    similarity_with_user = cosine_sim_df[user]\n",
    "    similarity_with_user = similarity_with_user.drop(user)\n",
    "\n",
    "    # Predict ratings for user\n",
    "    weighted_ratings = matrix.mul(similarity_with_user, axis=0).sum(axis=0) / similarity_with_user.sum()\n",
    "    predicted_ratings = weighted_ratings\n",
    "\n",
    "    # Exclude movies already rated by user\n",
    "    unrated_movies = matrix.loc[user] == 0\n",
    "    predicted_ratings_for_unrated_movies = predicted_ratings[unrated_movies]\n",
    "\n",
    "    top_10_movies = predicted_ratings_for_unrated_movies.sort_values(ascending=False).head(10)\n",
    "    return top_10_movies\n",
    "\n",
    "top_10_movies = compute_for_user(6, sample_rating_matrix)\n",
    "end = time.time()\n",
    "\n",
    "print(\"Top 10 movies recommended for User 6:\")\n",
    "print(top_10_movies)\n",
    "print(\"Execution time of the program is: \", end-start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity_optimized(matrix):\n",
    "    # Convert to sparse matrix\n",
    "    sparse_matrix = csr_matrix(matrix)\n",
    "\n",
    "    # Compute the magnitude for each user vector\n",
    "    magnitude = norm(sparse_matrix, axis=1)\n",
    "\n",
    "    # Normalize each vector to unit norm\n",
    "    unit_matrix = sparse_matrix.multiply(1 / magnitude.reshape(-1, 1))\n",
    "\n",
    "    # Compute cosine similarity\n",
    "    return unit_matrix.dot(unit_matrix.T).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 movies recommended for User 6:\n",
      "Name\n",
      "American Beauty                          2.871258\n",
      "Ghost                                    2.326168\n",
      "Speed                                    2.084855\n",
      "Jaws                                     2.014155\n",
      "The Wizard of Oz: Collector's Edition    1.964019\n",
      "Patch Adams                              1.918758\n",
      "Being John Malkovich                     1.902401\n",
      "Sideways                                 1.891653\n",
      "National Lampoon's Vacation              1.890831\n",
      "Bend It Like Beckham                     1.845176\n",
      "dtype: float64\n",
      "Execution time of the program is:   0.14936017990112305\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "def compute_for_user(user, matrix):\n",
    "    # Calculate the cosine similarity matrix\n",
    "    cosine_sim_matrix = cosine_similarity_optimized(matrix)\n",
    "\n",
    "    cosine_sim_df = pd.DataFrame(cosine_sim_matrix, index=matrix.index, columns=matrix.index)\n",
    "\n",
    "    # Find the similarity values for user and exclude user \n",
    "    similarity_with_user = cosine_sim_df[user]\n",
    "    similarity_with_user = similarity_with_user.drop(user)\n",
    "\n",
    "    # Predict ratings for user\n",
    "    weighted_ratings = matrix.mul(similarity_with_user, axis=0).sum(axis=0) / similarity_with_user.sum()\n",
    "    predicted_ratings = weighted_ratings\n",
    "\n",
    "    # Exclude movies already rated by user\n",
    "    unrated_movies = matrix.loc[user] == 0\n",
    "    predicted_ratings_for_unrated_movies = predicted_ratings[unrated_movies]\n",
    "\n",
    "    top_10_movies = predicted_ratings_for_unrated_movies.sort_values(ascending=False).head(10)\n",
    "    return top_10_movies\n",
    "\n",
    "top_10_movies = compute_for_user(6, sample_rating_matrix)\n",
    "end = time.time()\n",
    "\n",
    "print(\"Top 10 movies recommended for User 6:\")\n",
    "print(top_10_movies)\n",
    "print(\"Execution time of the program is:  \", end-start)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see from the output of my two cosine_similarity functions, the results are slightly different - the #1 suggested movie of American beautiy has a \"score\" of 2.77 in the first result and 2.88 in the second. The Wizard of Oz is the 4th recommended movie in the first implementation while it is 5th in the second implementation. \n",
    "\n",
    "Reasons for slight differences: \n",
    "\n",
    "a. Treatment of Zeros:\n",
    "\n",
    "In the dense implementation (cosine_similarity), zeros are explicitly considered and filtered out for each pair of users being compared. This method calculates similarity based solely on the items that both users have rated.\n",
    "The sparse implementation (cosine_similarity_optimized) inherently ignores zeros since they are not stored in the sparse matrix format. This method focuses on the non-zero ratings but might include zeros in the normalization step across entire vectors.\n",
    "\n",
    "b. Normalization Process:\n",
    "\n",
    "The first method normalizes vectors by considering only non-zero elements, effectively altering the vector length during normalization. This approach changes the basis of comparison to focus strictly on commonly rated items.\n",
    "The sparse method normalizes each vector as a whole, including zeros. This can lead to a slightly different interpretation of user preferences, especially in rows with many zeros.\n",
    "\n",
    "While there are technical differences in how the dense and sparse implementations of cosine similarity handle the data, especially regarding zeros and normalization, these differences are usually minor in the context of a recommendation system. The primary goal is to identify general patterns of user preferences, and both methods effectively contribute to this goal, with the sparse method offering significant computational advantages (as you can tell by the total time it took the program to run)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
